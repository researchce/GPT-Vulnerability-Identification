# Experiment Console UI - README

## Overview

This repository contains a suite of Python applications designed for analyzing CVE (Common Vulnerabilities and Exposures) data using various methods including heuristic analysis, OpenAI's GPT models, and direct comparison methods. The primary entry point for these applications is the `ExperimentConsoleUI`, which provides a console-based interface for running different types of experiments.

## Table of Contents

1. [Getting Started](#getting-started)
2. [Environment Setup](#environment-setup)
3. [Running the Experiment Console UI](#running-the-experiment-console-ui)
4. [Experiment Types](#experiment-types)
5. [Detailed Component Descriptions](#detailed-component-descriptions)
   - [UploadDataExperimentManager](#uploaddataexperimentmanager)
   - [ModulesSearchExperiment](#modulessearchexperiment)
   - [DirectComparisonManager](#directcomparisonmanager)
   - [CveCheckerProxy](#cvecheckerproxy)
   - [MongoDBHandler](#mongodbhandler)
   - [GptCVEChecker](#gptcvechecker)
   - [TotalFailureAnalyzer](#totalfailureanalyzer)
   - [CVEDataAnalyzer](#cvedataanalyzer)
   - [String Comparison](#string-comparison)
6. [Configuration](#configuration)
7. [License](#license)

## Getting Started

To get started with these applications, follow the steps below to set up your environment and run the Experiment Console UI.

### Prerequisites

- Python 3.7+
- MongoDB instance (local or cloud-based)
- OpenAI API Key

### Installing Dependencies

Use the following command to install the required dependencies:

```bash
pip install -r requirements.txt

### Environment Setup

Configuration File
Create a configuration file (config.json) with the following structure:
```bash
{
    "connection_string": "your_mongodb_connection_string",
    "database_name": "your_database_name",
    "gptCVECheckerPrompt": "path/to/your/gptCVECheckerPrompt.txt",
    "cve_descriptions": "path/to/your/cve_descriptions.csv",
    "modules_test_file": "path/to/your/modules_test_file.json",
    "modules_results_file": "path/to/your/modules_results_file.json",
    "training_file_path": "path/to/your/training_file.json",
    "collection_heuristic": "your_heuristic_collection",
    "experiments": [
        {
            "json_file_path": "path/to/your/json_file.json",
            "collection_name": "your_collection_name",
            "key": "cves"
        }
    ]
}

### Setting Environment Variables
Set the CONFIG_PATH environment variable to the path of your config.json file:

```bash
export CONFIG_PATH=/path/to/your/config.json

Set the OPENAI_API_KEY environment variable to your OpenAI API key:
```bash
export OPENAI_API_KEY=your_openai_api_key

### Running the Experiment Console UI
To run the Experiment Console UI, execute the following command:

bash
python experiment_console_ui.py

### Experiment Types
The ExperimentConsoleUI provides the following experiments:

Database Generation: Uploads JSON data to MongoDB collections.
Modules Names Validation: Searches for modules in the database and optionally evaluates their vulnerabilities using OpenAI.
Modules Evaluation: Runs a full evaluation of modules' vulnerabilities.
Training Evaluation: Compares vulnerabilities against training data.
Set CONFIG_PATH Environment Variable: Allows setting the configuration file path from the console.
Exit: Exits the console application.

