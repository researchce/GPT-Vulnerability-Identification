import json
import os
import pandas as pd
from tabulate import tabulate  # Importing tabulate for formatted table output
from cveCheckerProxy import CveCheckerProxy, EvaluatorTypes
from mongoDBHandler import MongoDBHandler
from versions_comparator import analyzeEachModule

"""
This script manages the direct comparison of CVE (Common Vulnerabilities and Exposures) data using 
heuristic and GPT-3 full evaluations. It includes classes and functions to:
- Load and parse configuration files and JSON data.
- Fetch and analyze CVE data from a MongoDB database.
- Evaluate modules using heuristic and GPT-3 methods.
- Calculate and compare results, updating output files with results.

Classes:
- DirectComparisonManager: Manages the loading, evaluation, and comparison of CVE data.

Functions:
- load_config: Loads configuration from a JSON file.
- get_cves: Retrieves CVE data from loaded JSON.
- get_vulnerable_versions: Extracts vulnerable modules and versions from CVE data.
- count_vulnerabilities: Counts and returns various vulnerability metrics.
- print_vulnerability_summary: Prints a summary of vulnerability metrics.
- evaluateHeuristic: Evaluates a module using heuristic methods.
- calculateResults: Calculates TP, TN, FP, FN for analysis.
- extract_cve_info: Extracts specific CVE information and evaluates using both methods.
- update_result_file: Updates the result file with evaluation results.
- compare_vulnerabilities: Compares vulnerabilities and prints the comparison results.

Usage:
- Initialize DirectComparisonManager with the path to the configuration file.
- Call methods to evaluate and compare vulnerabilities, printing summaries and updating result files.
"""

class DirectComparisonManager:
    def __init__(self, config_path):
        # Load configuration and initialize components
        self.config = self.load_config(config_path)
        self.cveChecker = CveCheckerProxy(self.config["gptCVECheckerPrompt"], self.config["cve_descriptions"])
        self.mongo_handler = MongoDBHandler(self.config["connection_string"], self.config["database_name"])
        self.heuristicCollection = self.config["collection_heuristic"]
        
        # Load JSON data from the specified file path
        with open(self.config["training_file_path"], 'r') as file:
            self.data = json.load(file)

    def get_cves(self):
        # Return the 'cves' array from the JSON data
        return self.data.get("cves", [])

    def load_config(self, config_path):
        # Load configuration from a JSON file
        with open(config_path, "r") as f:
            config = json.load(f)
        return config

    def get_vulnerable_versions(self):
        # Get a list of vulnerable modules and their versions
        vulnerable_versions = []
        for cve in self.get_cves():
            is_vulnerable = cve.get("isVulnerable", {})
            if is_vulnerable.get("Vulnerable", False):
                module = is_vulnerable.get("Module", "Unknown")
                version = is_vulnerable.get("Version", "Unknown")
                vulnerable_versions.append((module, version))
        return vulnerable_versions

    def count_vulnerabilities(self):
        # Count the total number of experiments, vulnerable/true, vulnerable/false, and unique CVE-IDs
        cves = self.get_cves()
        total_experiments = len(cves)  # Total elements in the 'cves' array

        # Count the number of vulnerable and non-vulnerable elements
        count_vulnerable = sum(1 for cve in cves if cve.get("isVulnerable", {}).get("Vulnerable", False))
        count_not_vulnerable = total_experiments - count_vulnerable

        # Get the unique set of CVE-IDs
        unique_cves = {cve.get("CVE-ID") for cve in cves}

        # Prepare the result as a dictionary
        result = {
            "total_experiments": total_experiments,
            "vulnerable_true": count_vulnerable,
            "vulnerable_false": count_not_vulnerable,
            "unique_cve_ids": len(unique_cves),
        }

        # Convert the dictionary to a Pandas DataFrame
        df = pd.DataFrame([result])
        return df

    def print_vulnerability_summary(self):
        # Get the DataFrame from the count_vulnerabilities method
        df = self.count_vulnerabilities()

        # Print the DataFrame using tabulate for a clean output
        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))

    def evaluateHeuristic(self, cve_id, module, version, tolerationRate=0.45):
        # Evaluate a module using heuristic methods
        item = self.mongo_handler.find_document_by_cve_id(self.heuristicCollection, cve_id)
        result = analyzeEachModule(item, "", module, version, tolerationRate)
        return result

    def calculateResults(self, analyzedResults, expected, estimated):
        # Calculate TP, TN, FP, FN for analysis
        if expected == estimated:
            if estimated:
                analyzedResults["TP"] += 1
            else:
                analyzedResults["TN"] += 1
        else:
            if estimated:
                analyzedResults["FP"] += 1
            else:
                analyzedResults["FN"] += 1
        return analyzedResults

    def extract_cve_info(self, experiment):
        # Iterate over each CVE and extract specific information
        cve_info_list = []
        heuristic_res = {"TP": 0, "TN": 0, "FP": 0, "FN": 0}
        openai_res = {"TP": 0, "TN": 0, "FP": 0, "FN": 0}
        for cve in self.get_cves():
            # Extract the relevant details
            cve_id = cve.get("CVE-ID", "Unknown")
            is_vulnerable = cve.get("isVulnerable", {})
            module = is_vulnerable.get("Module", "Unknown")
            version = is_vulnerable.get("Version", "Unknown")
            vulnerable_status = is_vulnerable.get("Vulnerable", False)
            print(f"Evaluating {cve_id} {module} {version} expected result {vulnerable_status}")
            vulnerable_result_openai = self.cveChecker.evaluate_module_gpt3full(cve_id, module, version)
            vulnerable_result_heuristic = self.evaluateHeuristic(cve_id, module, version)
            openai_res = self.calculateResults(openai_res, vulnerable_status, vulnerable_result_openai)
            heuristic_res = self.calculateResults(heuristic_res, vulnerable_status, vulnerable_result_heuristic)
            
            # Create a dictionary with the extracted information
            cve_info = {
                "CVE-ID": cve_id,
                "Module": module,
                "Version": version,
                "Vulnerable": vulnerable_status,
                "Vulnerable_Result_OPENAI": vulnerable_result_openai,
                "Vulnerable_Result_Heuristic": vulnerable_result_heuristic,
                "Match_OPENAI": vulnerable_status == vulnerable_result_openai,
                "Match_Heuristic": vulnerable_status == vulnerable_result_heuristic
            }
            cve_info_list.append(cve_info)  # Add the dictionary to the list
            print(f"Results \nOpenAI: {openai_res}\nHeuristic {heuristic_res}")
            
            # Update the result file for each item
            self.update_result_file("match_training_results-" + str(experiment) + ".json", cve_info)  # Call the new function

        return cve_info_list, openai_res, heuristic_res

    def update_result_file(self, result_file_path, cve_info):
        # Load existing data from the result file, if it exists
        if os.path.exists(result_file_path):
            with open(result_file_path, 'r') as file:
                existing_data = json.load(file)
        else:
            existing_data = []

        # Append the new data to the existing data
        existing_data.append(cve_info)

        # Write back to the JSON file to save the updated results
        with open(result_file_path, 'w') as file:
            json.dump(existing_data, file, indent=4)

    def compare_vulnerabilities(self, experiment):
        # Compare vulnerabilities and print the comparison results
        cve_info_list, openai_res, heuristic_res = self.extract_cve_info(experiment)  # Get the extracted info

        # Count the total number of matches and non-matches
        total_tests = len(cve_info_list)
        matches_openai = sum(1 for item in cve_info_list if item["Match_OPENAI"])
        non_matches_openai = total_tests - matches_openai
        matches_heuristic = sum(1 for item in cve_info_list if item["Match_Heuristic"])
        non_matches_heuristic = total_tests - matches_heuristic
        
        # Save results to a JSON file
        with open("experiment-" + str(experiment) + "-results.json", 'w') as file:
            json.dump({"openai": openai_res, "heuristic": heuristic_res}, file, indent=4)
        
        # Print the statistics
        print(f"Experiment: {experiment}")
        print(f"Total Tests: {total_tests}")
        print(f"Matches OpenAI: {matches_openai}")
        print(f"Non-Matches OpenAI: {non_matches_openai}")
        print(f"Matches Heuristic: {matches_heuristic}")
        print(f"Non-Matches Heuristic: {non_matches_heuristic}")
        print(f"Res Heuristic: {heuristic_res}")
        print(f"Res OpenAI: {openai_res}")
